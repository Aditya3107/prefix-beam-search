{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prefix_beam_search(ctc, beam_width=25, n_best=None, prune=0.001):\n",
    "\n",
    "\n",
    "    T, F = ctc.shape\n",
    "    ctc = np.vstack((np.zeros(F), ctc))\n",
    "    T, F = ctc.shape\n",
    "\n",
    "    # STEP 1: Initiliazation\n",
    "    O = ''\n",
    "    Pb, Pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    Pb[0][O] = 1\n",
    "    Pnb[0][O] = 0\n",
    "    A_prev = [O]\n",
    "\n",
    "    # STEP 2: Iterations and pruning\n",
    "    for t in range(1, T):\n",
    "        pruned_alphabet = [alphabet[i] for i in np.where(ctc[t] > prune)[0]]\n",
    "        for l in A_prev:\n",
    "            if len(l) > 0 and l[-1] == '>':\n",
    "                Pb[t][l] = Pb[t - 1][l]\n",
    "                Pnb[t][l] = Pnb[t - 1][l]\n",
    "                continue  \n",
    "            for c in pruned_alphabet:\n",
    "\n",
    "                # STEP 3: “Extending” with a blank\n",
    "                if c == '%':\n",
    "                    Pb[t][l] += ctc[t][-1] * (Pb[t - 1][l] + Pnb[t - 1][l])\n",
    "\n",
    "                # STEP 4: Extending with the end character\n",
    "                else:\n",
    "                    l_plus = l + c\n",
    "                    if len(l) > 0 and c == l[-1]:\n",
    "                        Pnb[t][l_plus] += ctc[t][self._token_map[c]] * Pb[t - 1][l]\n",
    "                        Pnb[t][l] += ctc[t][self._token_map[c]] * Pnb[t - 1][l]\n",
    "\n",
    "                    # STEP 5: Extending with any other non-blank character and LM constraints\n",
    "                    elif len(l.replace(' ', '')) > 0 and c in (' ', '>'):\n",
    "                        lm_prob = lm(l_plus) ** alpha\n",
    "                        Pnb[t][l_plus] += lm_prob * ctc[t][self._token_map[c]] * (Pb[t - 1][l] + Pnb[t - 1][l])\n",
    "                    else:\n",
    "                        Pnb[t][l_plus] += ctc[t][self._token_map[c]] * (Pb[t - 1][l] + Pnb[t - 1][l])\n",
    "\n",
    "                  # STEP 6: Make use of discarded prefixes\n",
    "                  if l_plus not in A_prev:\n",
    "                      Pb[t][l_plus] += ctc[t][-1] * (Pb[t - 1][l_plus] + Pnb[t - 1][l_plus])\n",
    "                      Pnb[t][l_plus] += ctc[t][self._token_map[c]] * Pnb[t - 1][l_plus]\n",
    "\n",
    "      # STEP 7: Select most probable prefixes\n",
    "      A_next = Pb[t] + Pnb[t]\n",
    "      sorter = lambda l: A_next[l] * (len(self.W(l)) + 1) ** self.beta\n",
    "      A_prev = sorted(A_next, key=sorter, reverse=True)[:beam_width]\n",
    "\n",
    "\n",
    "  if n_best is None:\n",
    "      return tokenizer(A_prev[0].strip('>'))\n",
    "  else:\n",
    "      return [(tokenizer(l.strip('>')), sorter(l)) for l in A_prev[:n_best]]\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    for example_file in glob('examples/*.p'):\n",
    "        example = pickle.load(open(example_file, 'rb'))\n",
    "        before_lm = greedy_decoder(example)\n",
    "        after_lm = prefix_beam_search(example)\n",
    "        print('\\nBEFORE:\\n{}'.format(before_lm))\n",
    "        print('\\nAFTER:\\n{}'.format(before_lm))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
